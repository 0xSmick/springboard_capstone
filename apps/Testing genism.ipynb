{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import nltk.data\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "\n",
    "def connect_db():\n",
    "\treturn sqlite3.connect('/Users/sheldon/podcasts/test.db')\n",
    "\n",
    "def create_df_object():\n",
    "\tconn = sqlite3.connect('/Users/sheldon/podcasts/test.db')\n",
    "\tdf = pd.read_sql(\"select * from podcast\",conn)\n",
    "\treturn df\n",
    "\n",
    "df = create_df_object()\n",
    "\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.head()\n",
    "import psycopg2\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://sheldon@localhost:5432/sheldon')\n",
    "df1 = pd.read_sql(\"select * from podcasts\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    select *\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df1.query(\"select *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(row):\n",
    "    tokens = word_tokenize(str(row))\n",
    "    tokens = [w for w in tokens if not w in stop]\n",
    "    tokens = [word for word in tokens if not \"'\" in word]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['transcribed'] = df['transcribed'].apply(remove_stop_words)\n",
    "texts = df.transcribed.tolist()\n",
    "\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] +=1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class MyCorpus(object):\\n    def __iter__(self):\\n        for doc in docs:\\n            yield dictionary.doc2bow(doc.split())\\ncorpus_mem_friendly = MyCorpus()\\ncorpora.MmCorpus.serialize(\\'corpus.mm\\',corpus_mem_friendly)\\ndictionary.save(\\'words.dict\\')\\ndf[\"review_text\"] = df[\"transcribed\"].map(lambda x: x.split(\\' \\'))\\nfrom gensim import corpora\\ndictionary = corpora.Dictionary(df[\"review_text\"])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for doc in docs:\n",
    "            yield dictionary.doc2bow(doc.split())\n",
    "corpus_mem_friendly = MyCorpus()\n",
    "corpora.MmCorpus.serialize('corpus.mm',corpus_mem_friendly)\n",
    "dictionary.save('words.dict')\n",
    "df[\"review_text\"] = df[\"transcribed\"].map(lambda x: x.split(' '))\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(df[\"review_text\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '%'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2343d514bd53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load all the stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/words.dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMmCorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/corpus.mm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidfmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTfidfModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/tfidf_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsimodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/model.lsi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sheldon/anaconda/envs/capstone/lib/python2.7/site-packages/gensim/utils.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sheldon/anaconda/envs/capstone/lib/python2.7/site-packages/gensim/utils.pyc\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '%'."
     ]
    }
   ],
   "source": [
    "#load all the stuff\n",
    "dictionary = corpora.Dictionary.load('models/words.dict')\n",
    "corpus = corpora.MmCorpus.load('models/corpus.mm')\n",
    "tfidf = gensim.models.tfidfmodel.TfidfModel.load('models/tfidf_model')\n",
    "lsi = gensim.models.lsimodel.LsiModel.load('models/model.lsi')\n",
    "index = similarities.MatrixSimilarity.load('models/corpus.index')\n",
    "lda = gensim.models\n",
    "#tfidf.save('tfidf_model')\n",
    "lsi.save('models/model.lsi')\n",
    "#tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "#lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=75)\n",
    "corpus_lsi = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-b3a4dec5989c>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-b3a4dec5989c>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    listOfTopics =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_related_podcasts(index):\n",
    "    def getKey(item):\n",
    "        return item[1]\n",
    "    listOfTopics = \n",
    "    corpus = corpus_lsi[index]\n",
    "    corpus = sorted(corpus, key=getKey, reverse=True)[0:10]\n",
    "    related_df = pd.DataFrame(corpus,columns=['index','score'])\n",
    "    final_df = pd.merge(related_df, df, on='index')[['index','episode','score','series']]\n",
    "    return final_df\n",
    "\n",
    "get_related_podcasts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'economics', 0.20075241030479216),\n",
       " (u'economists', 0.096918993194952341),\n",
       " (u'gender', 0.086645740787323997),\n",
       " (u'offender', 0.080986352314974794),\n",
       " (u'coin', 0.068897077342306143),\n",
       " (u'offenders', 0.068654664387510944),\n",
       " (u'marijuana', 0.068175380206256297),\n",
       " (u'apron', 0.066312516353626047),\n",
       " (u'financial', 0.062462980433143037),\n",
       " (u'education', 0.061449591429715587),\n",
       " (u'police', 0.061018826813492695),\n",
       " (u'petty', 0.059712896718308241),\n",
       " (u'preferences', 0.056998621035908949),\n",
       " (u'assaulting', 0.055874036704667569),\n",
       " (u'charities', 0.054803188035918111),\n",
       " (u'kidney', 0.0544317951725444),\n",
       " (u'officer', 0.052501476182249304),\n",
       " (u'caleb', 0.052433083247781884),\n",
       " (u'diploma', 0.050797805357103633),\n",
       " (u'registry', 0.050217514569610322),\n",
       " (u'giants', 0.050112168659068236),\n",
       " (u'driver', 0.048065446698679702),\n",
       " (u'reaganomics', 0.046414306760494413),\n",
       " (u'game', 0.045799533122943097),\n",
       " (u'economist', 0.045648828501652632),\n",
       " (u'crime', 0.044992693069287437),\n",
       " (u'diplomas', 0.044448079687465711),\n",
       " (u'radio', 0.044157869116420258),\n",
       " (u'currency', 0.043632198572000444),\n",
       " (u'cowboys', 0.043251296345787796),\n",
       " (u'utopia', 0.042731704755242149),\n",
       " (u'tommy', 0.042726015553238447),\n",
       " (u'steve', 0.042248189766779923),\n",
       " (u'alcohol', 0.042056066901713353),\n",
       " (u'games', 0.041866191450996126),\n",
       " (u'trophy', 0.041702718345644214),\n",
       " (u'carolina', 0.041576761668042375),\n",
       " (u'preference', 0.041406695996573532),\n",
       " (u'packers', 0.040655820422947908),\n",
       " (u'denver', 0.040584694736775735),\n",
       " (u'freak', 0.040476103140352888),\n",
       " (u'trophies', 0.0389693134498569),\n",
       " (u'thump', 0.038741618715308276),\n",
       " (u'bono', 0.038338917796152283),\n",
       " (u'firstborn', 0.037978874195838147),\n",
       " (u'hargreaves', 0.03764094449513268),\n",
       " (u'gift', 0.037495529218878103),\n",
       " (u'restrooms', 0.037270876644085002),\n",
       " (u'mortified', 0.036611151467359319),\n",
       " (u'pittsburgh', 0.036132237090812522),\n",
       " (u'chicago', 0.036118557649630158),\n",
       " (u'mortgages', 0.03608682634714637),\n",
       " (u'pornography', 0.036065406294734731),\n",
       " (u'morgan', 0.035849356936325023),\n",
       " (u'blog', 0.035848506091984936),\n",
       " (u'sex', 0.035681433053336195),\n",
       " (u'sister', 0.035546112638106628),\n",
       " (u'crimes', 0.035543037065394176),\n",
       " (u'minus', 0.035494555582051744),\n",
       " (u'tribune', 0.034926183742266491),\n",
       " (u'criminal', 0.034920818902150597),\n",
       " (u'charges', 0.03489386369348807),\n",
       " (u'markets', 0.034731668978308303),\n",
       " (u'jets', 0.033874664078435396),\n",
       " (u'degree', 0.033866707790161196),\n",
       " (u'dean', 0.033815812714591047),\n",
       " (u'stanley', 0.03370301132013459),\n",
       " (u'minnesota', 0.03333750931794318),\n",
       " (u'paddy', 0.033144301705865811),\n",
       " (u'sesame', 0.032815701742337736),\n",
       " (u'zoom', 0.032460020806240768),\n",
       " (u'embarking', -0.032504793891144711),\n",
       " (u'donald', -0.033636813452894584),\n",
       " (u'improving', -0.033735014880266589),\n",
       " (u'shane', -0.034054833765613128),\n",
       " (u'ladies', -0.03477144701118861),\n",
       " (u'genetic', -0.035370858950304208),\n",
       " (u'patient', -0.035657589553726811),\n",
       " (u'medication', -0.036161178193132575),\n",
       " (u'hype', -0.03704937890596121),\n",
       " (u'asia', -0.037416770020017948),\n",
       " (u'ha', -0.037651017605805283),\n",
       " (u'polls', -0.037791308688583568),\n",
       " (u'franklin', -0.037857829243672328),\n",
       " (u'diabetes', -0.04025621090744548),\n",
       " (u'black', -0.040731944805092277),\n",
       " (u'republican', -0.040976605810292319),\n",
       " (u'trump', -0.041859603230542157),\n",
       " (u'queen', -0.043730798342776406),\n",
       " (u'shame', -0.044976328399778727),\n",
       " (u'hap', -0.045146926700645996),\n",
       " (u'movies', -0.051521539418352212),\n",
       " (u'cream', -0.051756938493142189),\n",
       " (u'swiss', -0.056873965391394714),\n",
       " (u'philadelphia', -0.062535190303895261),\n",
       " (u'movie', -0.065527781760655185),\n",
       " (u'health', -0.065892805668891316),\n",
       " (u'patients', -0.097967991649763622),\n",
       " (u'vulnerability', -0.10969328881746618),\n",
       " (u'queens', -0.11206711629168782)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics(num_words=100)[1]\n",
    "def getKey(item):\n",
    "        return item[1]\n",
    "sorted(corpus_lsi[17], key=getKey,reverse=True)\n",
    "sorted(lsi.show_topic(8,topn=100), key=getKey, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.17896380730880518),\n",
       " (21, 0.091766397149891432),\n",
       " (11, 0.065616352648861648),\n",
       " (13, 0.064971534129887182),\n",
       " (18, 0.025042972421945916),\n",
       " (14, 0.024075613086501517),\n",
       " (6, 0.015937881772443523),\n",
       " (3, 0.01362197571894958),\n",
       " (5, 0.013074554462267355),\n",
       " (4, 0.0088382479607463076),\n",
       " (9, 0.0022015115732176059),\n",
       " (19, -0.027478503662382983),\n",
       " (1, -0.033732093283322856),\n",
       " (2, -0.03667141346621143),\n",
       " (17, -0.043455623803401247),\n",
       " (7, -0.043792188330803443),\n",
       " (15, -0.045263199178342921),\n",
       " (16, -0.045927792542153609),\n",
       " (12, -0.07568664639746138),\n",
       " (22, -0.081326541458310503),\n",
       " (24, -0.10229900073505233),\n",
       " (0, -0.11914869474184712),\n",
       " (10, -0.13419026138406509),\n",
       " (23, -0.20864550487239134),\n",
       " (20, -0.23951662981995908)]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gettting Related Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -0.30666008595379457),\n",
       " (1, -0.11729049248029232),\n",
       " (2, 0.09465178780371751),\n",
       " (3, 0.1021867895086989),\n",
       " (4, -0.055071455362356046),\n",
       " (5, 0.042427461451872366),\n",
       " (6, -0.099190452301410284),\n",
       " (7, -0.15977382403279178),\n",
       " (8, -0.19050174225760189),\n",
       " (9, 0.11962812051264791),\n",
       " (10, -0.062988823786490372),\n",
       " (11, 0.15656530181930398),\n",
       " (12, -0.088286265017136933),\n",
       " (13, -0.068219332021130799),\n",
       " (14, 0.074681883889618314),\n",
       " (15, -0.010344141539310351),\n",
       " (16, -0.011351173648180354),\n",
       " (17, 0.045443599720397507),\n",
       " (18, 0.011356358861277709),\n",
       " (19, 0.020344898048179155),\n",
       " (20, 0.016910421609358444),\n",
       " (21, -0.007355589844098882),\n",
       " (22, -0.032113079486917967),\n",
       " (23, -0.047263684081847689),\n",
       " (24, 0.0025554615751745072)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lsi[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_related_podcasts(index):\n",
    "    def getKey(item):\n",
    "        return item[1]\n",
    "    corpus = corpus_lsi[index]\n",
    "    corpus = sorted(corpus, key=getKey, reverse=True)[0:10]\n",
    "    related_df = pd.DataFrame(corpus,columns=['index','score'])\n",
    "    final_df = pd.merge(related_df, df, on='index')[['index','episode','score','series']]\n",
    "    return final_df\n",
    "\n",
    "related_podcasts = list(get_related_podcasts(1)['index'])\n",
    "\n",
    "def get_topics_per_podcast(podcast_index):\n",
    "    topic_ids = [i for i in sorted(corpus_lsi[podcast_index], key=getKey, reverse=True) if i[1] > 0.10]\n",
    "    def get_topic_arrays(topic_ids):\n",
    "        x = []\n",
    "        for id in topic_ids:\n",
    "            list_of_words = sorted(lsi.show_topic(id[0], topn=5),key=getKey, reverse=True)\n",
    "            z = []\n",
    "            for word in list_of_words:\n",
    "                if word[1] > .05:\n",
    "                    z.append(word)\n",
    "            x.append(z)\n",
    "        return x\n",
    "    topic_arrays = get_topic_arrays(topic_ids)\n",
    "    return topic_arrays\n",
    "testing = [[related_podcasts[i],get_topics_per_podcast(related_podcasts[i])] for i in range(0, len(related_podcasts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'tommy', 0.13349055465001164),\n",
       "  (u'petrified', 0.13210484035640158),\n",
       "  (u'elkins', 0.12485860653687339),\n",
       "  (u'trump', 0.11205463919933509)],\n",
       " [(u'lakeview', 0.16230038683391426), (u'chandler', 0.13397388194476367)],\n",
       " [(u'dean', 0.15605057080987761), (u'police', 0.097709114659441917)],\n",
       " [(u'movie', 0.19523593887426033),\n",
       "  (u'movies', 0.13411589375868901),\n",
       "  (u'assaulting', 0.092371566597563279)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing\n",
    "x = pd.DataFrame(testing, columns=['index','words'])\n",
    "x.words.ix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Related documents based on query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_related_podcasts(query):\n",
    "    vec_box = dictionary.doc2bow(query.split())\n",
    "    vec_lsi = lsi[vec_box]\n",
    "    sims = index[vec_lsi]\n",
    "    sims = sorted(enumerate(sims), key=lambda item: -item[1])[0:10]\n",
    "    related_df = pd.DataFrame(sims,columns=['index','score'])\n",
    "    def get_related_podcasts_list(index):\n",
    "        def getKey(item):\n",
    "            return item[1]\n",
    "        corpus = corpus_lsi[index]\n",
    "        corpus = sorted(corpus, key=getKey, reverse=True)[0:10]\n",
    "        related_df = pd.DataFrame(corpus,columns=['index','score'])\n",
    "        final_df = pd.merge(related_df, df, on='index')[['index','episode','score','series']]\n",
    "        return final_df\n",
    "\n",
    "    related_podcasts = list(get_related_podcasts_list(1)['index'])\n",
    "\n",
    "    def get_topics_per_podcast(podcast_index):\n",
    "        topic_ids = [i for i in sorted(corpus_lsi[podcast_index], key=getKey, reverse=True) if i[1] > 0.10]\n",
    "        def get_topic_arrays(topic_ids):\n",
    "            x = []\n",
    "            for id in topic_ids:\n",
    "                list_of_words = sorted(lsi.show_topic(id[0], topn=5),key=getKey, reverse=True)\n",
    "                z = []\n",
    "                for word in list_of_words:\n",
    "                    if word[1] > .05:\n",
    "                        z.append(word)\n",
    "                x.append(z)\n",
    "            return x\n",
    "        topic_arrays = get_topic_arrays(topic_ids)\n",
    "        return topic_arrays\n",
    "    topics_per_podcast = [[related_podcasts[i],get_topics_per_podcast(related_podcasts[i])] for i in range(0, len(related_podcasts))]\n",
    "    other_df = pd.DataFrame(topics_per_podcast, columns=['topic_index','words'])\n",
    "    final_df = pd.merge(related_df, df)\n",
    "    test_final_df = pd.merge(other_df, final_df,left_index=True,right_index=True)[['words','index','score','episode','series']]\n",
    "    return test_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = get_related_podcasts('cats')\n",
    "zz = x.words.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'lakeview', 0.16230038683391426), (u'chandler', 0.13397388194476367)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.291095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>0.225385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0.218698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.197811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.185274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>0.174860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>0.160806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>0.159709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>0.139874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>0.128635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>0.124274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>0.119610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>0.111168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>0.108407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>0.091393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>0.054864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>89</td>\n",
       "      <td>0.023582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>0.022864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78</td>\n",
       "      <td>0.008958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>62</td>\n",
       "      <td>-0.021017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>119</td>\n",
       "      <td>-0.025039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74</td>\n",
       "      <td>-0.027536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>121</td>\n",
       "      <td>-0.031408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>137</td>\n",
       "      <td>-0.037055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>68</td>\n",
       "      <td>-0.037749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>115</td>\n",
       "      <td>-0.037889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>122</td>\n",
       "      <td>-0.039599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>99</td>\n",
       "      <td>-0.042506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65</td>\n",
       "      <td>-0.048880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>47</td>\n",
       "      <td>-0.194450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.195210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.197204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>107</td>\n",
       "      <td>-0.197657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>45</td>\n",
       "      <td>-0.201181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.201359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.201887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>101</td>\n",
       "      <td>-0.203043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>149</td>\n",
       "      <td>-0.204315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>112</td>\n",
       "      <td>-0.204922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.205141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.205235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>150</td>\n",
       "      <td>-0.205884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>147</td>\n",
       "      <td>-0.208164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.208597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>53</td>\n",
       "      <td>-0.209838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.210375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.210404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>108</td>\n",
       "      <td>-0.212018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>104</td>\n",
       "      <td>-0.214856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>148</td>\n",
       "      <td>-0.216398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>102</td>\n",
       "      <td>-0.216993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.221978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.222895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>109</td>\n",
       "      <td>-0.222942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.225827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>105</td>\n",
       "      <td>-0.230408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>106</td>\n",
       "      <td>-0.231272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>111</td>\n",
       "      <td>-0.236596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>103</td>\n",
       "      <td>-0.241512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      rank\n",
       "0     20  0.291095\n",
       "1     29  0.225385\n",
       "2     23  0.218698\n",
       "3     30  0.197811\n",
       "4     22  0.185274\n",
       "5     17  0.174860\n",
       "6     24  0.160806\n",
       "7     34  0.159709\n",
       "8     26  0.139874\n",
       "9     28  0.128635\n",
       "10    25  0.124274\n",
       "11    21  0.119610\n",
       "12    27  0.111168\n",
       "13    32  0.108407\n",
       "14    18  0.091393\n",
       "15    31  0.054864\n",
       "16    89  0.023582\n",
       "17    33  0.022864\n",
       "18    78  0.008958\n",
       "19    19 -0.003617\n",
       "20    62 -0.021017\n",
       "21   119 -0.025039\n",
       "22    74 -0.027536\n",
       "23   121 -0.031408\n",
       "24   137 -0.037055\n",
       "25    68 -0.037749\n",
       "26   115 -0.037889\n",
       "27   122 -0.039599\n",
       "28    99 -0.042506\n",
       "29    65 -0.048880\n",
       "..   ...       ...\n",
       "121   47 -0.194450\n",
       "122    0 -0.195210\n",
       "123    3 -0.197204\n",
       "124  107 -0.197657\n",
       "125   45 -0.201181\n",
       "126   12 -0.201359\n",
       "127    8 -0.201887\n",
       "128  101 -0.203043\n",
       "129  149 -0.204315\n",
       "130  112 -0.204922\n",
       "131   54 -0.205141\n",
       "132   50 -0.205235\n",
       "133  150 -0.205884\n",
       "134  147 -0.208164\n",
       "135    1 -0.208597\n",
       "136   53 -0.209838\n",
       "137    9 -0.210375\n",
       "138   52 -0.210404\n",
       "139  108 -0.212018\n",
       "140  104 -0.214856\n",
       "141  148 -0.216398\n",
       "142  102 -0.216993\n",
       "143    7 -0.221978\n",
       "144    5 -0.222895\n",
       "145  109 -0.222942\n",
       "146   86 -0.225827\n",
       "147  105 -0.230408\n",
       "148  106 -0.231272\n",
       "149  111 -0.236596\n",
       "150  103 -0.241512\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words=stop)\n",
    "tfidf_matrix = tf.fit_transform(df['transcribed'])\n",
    "copy_matrix = tf.transform(df['transcribed'])\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = 'python economics love'\n",
    "trans_query = query.lower()\n",
    "trans_query = query.split()\n",
    "tfidf_matrix_test = tf.fit_transform(trans_query)\n",
    "tfidf_matrix_train = tf.transform(df['transcribed'])\n",
    "tfidf_matrix_train.todense()\n",
    "tfidf_matrix_test.todense()\n",
    "query_similarities = linear_kernel(tfidf_matrix_test, tfidf_matrix_train)\n",
    "query_similarities = query_similarities.argsort()[0][::-1]\n",
    "pod_dict = dict(zip(range(0, len(query_similarities)),query_similarities))\n",
    "pod_dict = pd.DataFrame({'rank':pod_dict.keys()}, index=pod_dict.values())\n",
    "#related_podcasts_df = pd.DataFrame.join(pod_dict, df, how='inner')\n",
    "#final_df = related_podcasts_df.sort_values('rank')[1:11][['rank','episode','series']]\n",
    "#related_podcasts = final_df['episode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank\n",
       "148     0\n",
       "113     1\n",
       "150     2\n",
       "45      3\n",
       "52      4\n",
       "51      5\n",
       "50      6\n",
       "49      7\n",
       "48      8\n",
       "47      9\n",
       "46     10\n",
       "44     11\n",
       "54     12\n",
       "43     13\n",
       "42     14\n",
       "41     15\n",
       "40     16\n",
       "39     17\n",
       "38     18\n",
       "53     19\n",
       "55     20\n",
       "36     21\n",
       "56     22\n",
       "71     23\n",
       "70     24\n",
       "69     25\n",
       "68     26\n",
       "67     27\n",
       "66     28\n",
       "65     29\n",
       "..    ...\n",
       "86    121\n",
       "85    122\n",
       "84    123\n",
       "83    124\n",
       "82    125\n",
       "81    126\n",
       "80    127\n",
       "79    128\n",
       "78    129\n",
       "77    130\n",
       "76    131\n",
       "91    132\n",
       "92    133\n",
       "93    134\n",
       "102   135\n",
       "108   136\n",
       "107   137\n",
       "106   138\n",
       "105   139\n",
       "104   140\n",
       "103   141\n",
       "101   142\n",
       "94    143\n",
       "100   144\n",
       "99    145\n",
       "98    146\n",
       "97    147\n",
       "96    148\n",
       "95    149\n",
       "0     150\n",
       "\n",
       "[151 rows x 1 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
